{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zulfiqaralimir/Geo-Spacial-Data/blob/master/Satellite_Imagery_for_Financial_Applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Satellite Imagery**"
      ],
      "metadata": {
        "id": "YVUgwQAw3Osc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Satellite Imagery**\n",
        "\n",
        "|  |  |\n",
        "|:---|:---|\n",
        "|**Prior Knowledge** |Basic Python|\n",
        "|**Keywords** |Remote sensing, Electromagnetic spectrum, Spatial resolution\n",
        " |\n",
        "|  |  |"
      ],
      "metadata": {
        "id": "iGi4oVbT4wlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Introduction**\n",
        "\n",
        "We are going to introduce a type of data that we have not touched upon yet: **satellite imagery**. Traditionally, satellite images are the type of data used in natural sciences or the defense sector. However, in recent years, more and more financial analysts have been using satellite images to conduct analyses, hoping to gain extra insights on top of traditional financial analysis to make better financial decisions. We will use **Google Earth Engine** (GEE) to access some satellite images and provide examples of how we can use satellite images for analysis.\n",
        "\n",
        "## **2. Financial Application of Satellite Imagery**\n",
        "\n",
        "In this section, we are going to talk about how to incorporate satellite images as part of data for financial analysis.\n",
        "<br>\n",
        "\n",
        "##**First Application**\n",
        "One of the most famous cases of using satellite images for financial analysis is to use satellite images to count the number of cars in and out of **Walmart stores' parking lots** over a period of time. Financial analysts use this piece of information as a **proxy of foot traffic** to gauge the sales of the store during a specific period of time. This leads to the first application of using satellite images.\n",
        "<br>\n",
        "<br>\n",
        "### **2.1 Monitoring Economic Activities of a Location**\n",
        "The Walmart parking lot example is a classic application of satellite imagery. Another example is to use satellite images to monitor container ship traffic at a major canal or a major port to identify possible supply chain obstacles. We can also use satellite images to monitor factory sites to evaluate potential production levels of a certain time. We can also monitor a mining site to **track commodity production**.\n",
        "<br>\n",
        "<br>\n",
        "### **2.2 Tracking Crop Yield**\n",
        "We can use satellite images to study if a given crop, like wheat or corn, is healthy or not. From this information, financial analysts can estimate if the market is going to have an oversupply of a crop or a shortage of a crop and trade on this information. We usually would use a **combination of infrared bands** to conduct this analysis.\n",
        "<br>\n",
        "<br>\n",
        "###**2.3 Investigating Damages of Natural Disasters**\n",
        "**Insurance companies** now use satellite images to access damages from a flood or a wildfire. This method of gathering damage information is more effective than traditional methods of visiting the damage sites. First, the traditional method may require several months to gather data, but using satellite images only takes a few hours. Secondly, many damage sites are usually not accessible after a disaster, so the traditional method is not possible.\n",
        "With this new satellite image technology, insurance companies are able to process insurance claims faster and in more cost-effective ways.\n",
        "<br>\n",
        "<br>\n",
        "###**2.4 Constraints of Using Satellite Imagery for Financial Analysis**\n",
        "Currently, for the general public, there are a few issues when it comes to using satellite images for investment analysis.\n",
        "<br>\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;(A) The temporal resolutions for public available satellite images can be long. For example, Landsat 9 has a temporal resolution of 8 days. Many commercial satellites offer satellite images with short temporal resolution, like a day. However, they are **expensive**.\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;(B) Processing large amount of satellite images requires powerful computing infrastructure, which individuals usually don't have.\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;(C) Processing raw satellite images and converting them into usable images requires **special training**.\n",
        "<br>\n",
        "<br>\n",
        "Due to these constraints in using satellite images for analysis, there are many companies that now offer service to access their analytical platforms for satellite images with a subscription. These companies collect public and private satellite images, process them, and then upload them to their platforms. Their platforms generally incorporate machine learning capabilities for analysis. However, the fees to access these platforms are high, so only **hedge funds** or **big investment companies** can access them. Take the example of using *retail parking lot car traffic as an indicator for stock trading*. It is still a profitable trading strategy, but only hedge funds will have access to this information.\n",
        "\n",
        "\n",
        "## **3. The Basics of Satellite Imagery**\n",
        "\n",
        "### **3.1 Remote Sensing**\n",
        "\n",
        "Before talking about satellite images, we need to introduce a few concepts. The first is remote sensing. **Remote sensing** is the activity of using Earth observation satellites or airplanes equipped with sensors to obtain images and other information about the Earth's surface from above.   \n",
        "\n",
        "The sensors on a satellite measure **electromagnetic radiation (EMR)**, which is first emitted by the sun. Once it reaches Earth's surface, it is then reflected back to the sensors on the satellite. Figure 1 below demonstrates the path of EMR movement.\n",
        "<br>\n",
        "<br>\n",
        "**Figure 1: Illustration of How a Satellite Measures EMR Reflected from Earth's Surface**\n",
        "![alt text](https://drive.google.com/uc?id=1yxfc54aY2juMY-IF7NgYX_iMIjOcGd-w)\n",
        "<br>\n",
        "Adapted from: NASA EarthData. \"What Is Remote Sensing?\" 10 December 2024. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "### **3.2 Electromagnetic Spectrum**\n",
        "\n",
        "EMR is a type of energy that travels in waves. However, these waves are not homogeneous; they have different wavelengths. The wavelength of a wave is measured as the distance between two wave tops. If one wave has a shorter wavelength than the other waves, then this wave has a higher frequency because the wave moves up and down and then up again faster.\n",
        "<br>\n",
        "We group waves with similar wavelengths into a band called a **spectrum**. Figure 2 below shows how we group waves into different spectrums or bands by their wavelengths.\n",
        "<br>\n",
        "\n",
        "\n",
        "### **3.3 Spatial Resolution**\n",
        "When a satellite collects information from an observation area, it divides the area into a matrix or a grid. Each cell in the matrix is called a **pixel**. A cell is a square. If the cell is square that is 30 meters x 30 meters, then the resolution is 30 meters. The number represents the size of a pixel. Figure 5 demonstrates this concept.\n",
        "\n",
        "**Figure 5: Spatial Resolution**\n",
        "![alt text](https://drive.google.com/uc?id=1tYbEt25rjMQjFv5IYpPOxQVVlMdQv6NS)\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "O_lNFfBOHZVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Satellite Imagery Application: Google Earth Engine**\n",
        "We are going to use the Google Earth Engine (GEE) platform to retrieve satellite images and do some analysis. Google Earth Engine is a platform that we can use to conduct analysis for satellite images and other geospatial data. The GEE team has collected and processed publicly available historical satellite images from popular satellites and stores them in its Earth Engine data catalog. Hence, we don't need to spend time and effort to collect and process raw historical satellite images. GEE has a code editor user interface that allows users to retrieve and analyze satellite images. It also has a Python API. We will use the Python API to retrieve images and conduct analysis.\n",
        "<br>\n",
        "<br>\n",
        "### **4.1 Scenario: 2018 Northern California Camp Fire**\n",
        "On Thursday, November 8, 2018, a faulty electric transmission line caught fire in Butte County, California, in the United States. Due to strong downslope wind, the fire spread quickly and burned around 153,000 acres of land. It did not stop until November 25, 2018. The Camp Fire was the most expensive natural disaster in 2018. In this section, we are going to look at the satellite images before the fire, during the fire, and after the fire. We will also do one analysis to investigate the vegetation conditions before and after the fire.\n",
        "<br>\n",
        "<br>\n",
        "### **4.2 Set Up Google Earth Engine**\n",
        "Before using Google Earth Engine, please read the file linked below. This file outlines how to set up a Google Earth Engine account step by step.\n",
        "\n",
        "https://docs.google.com/document/d/1xZwsOHp49aCQFsPzvP0Kd8SJGmwMZA9Q/edit?usp=drive_link&ouid=103990088807346702419&rtpof=true&sd=true\n",
        "\n",
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "Ac4VRDec4pFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Python API Demonstration on Google Colab**\n",
        "\n"
      ],
      "metadata": {
        "id": "bElUTJ-Epe5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.1 Load the Necessary Libraries for This Demonstration**#\n",
        "\n",
        "Access Python API for GEE."
      ],
      "metadata": {
        "id": "yumPFBkREeWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pandas to handle tabular data and geopandas to handle geospatial data\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "# earth engine\n",
        "import ee\n",
        "\n",
        "# Google earth engine map\n",
        "import geemap\n",
        "\n",
        "# allow images to display in the notebook\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "ub9rsw-1Sc8E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "96d4d08a-20a7-44f8-9db4-87bbb15a184d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.2 Access to Google Earth Engine**###\n",
        "We will use the following code to access Google Earth Engine's API. Please replace 'ee-si-learning-001' with your own project ID. Your Project ID was created when you registered for Google Earth Engine. During the authentication process, a dialogue box will appear. It will ask you to select the Google account you used to register for Google Earth Engine. Please click that account. Then, there will be some information along with a \"continue\" button on the lower right side of the dialogue box. Please click the \"continue\" button. Then, there will be another message, and you will need to go through and hit the \"continue\" button to finish the authentication process. There will be two continue buttons to hit in total."
      ],
      "metadata": {
        "id": "MF5yQtolcWHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Google Earth Engine authentication process\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize Google Earth Engine with the project ID you set up during the account set up step\n",
        "ee.Initialize(project='glassy-keyword-466113-d0')\n"
      ],
      "metadata": {
        "id": "L2QCQnOIcRUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "64d52fc2-d816-40df-a58c-1ce58bbc36f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <style>\n",
              "                .geemap-dark {\n",
              "                    --jp-widgets-color: white;\n",
              "                    --jp-widgets-label-color: white;\n",
              "                    --jp-ui-font-color1: white;\n",
              "                    --jp-layout-color2: #454545;\n",
              "                    background-color: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-dark .jupyter-button {\n",
              "                    --jp-layout-color3: #383838;\n",
              "                }\n",
              "\n",
              "                .geemap-colab {\n",
              "                    background-color: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "\n",
              "                .geemap-colab .jupyter-button {\n",
              "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
              "                }\n",
              "            </style>\n",
              "            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.3 Set Up Filter Parameters**###\n",
        "Define the location of interest using latitude and longitude coordinates as well as a start and end period to pull satellite images. We can use Google Maps to find latitude and longitude coordinates for Butte County in California. Since the fire started on November 8, 2018, we will pull the images from October 2018 to December 2018."
      ],
      "metadata": {
        "id": "CYszOAACdoeK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coordinates of the Camp Fire\n",
        "lat =  39.444012\n",
        "lon = -121.833619\n",
        "\n",
        "# point of interest as an ee.Geometry\n",
        "poi = ee.Geometry.Point(lon,lat)\n",
        "\n",
        "# start date of range to filter for\n",
        "start_date = '2018-10-01'\n",
        "\n",
        "# end date\n",
        "end_date = '2019-01-31'\n"
      ],
      "metadata": {
        "id": "STylTawXdfT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.4 Retrieve Images from Google Earth Engine Data Catalog**\n",
        "We will retrieve the images from Landsat 8. The following link from Google Earth Engine provides information about this image collection from Landsat 8. It also provides the Python code snippet to pull the images shown in the following code.\n",
        "<br>\n",
        "https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_L2\n"
      ],
      "metadata": {
        "id": "h_xz0LL1duji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the satellite data\n",
        "landsat = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\\\n",
        "            .filterBounds(poi)\\\n",
        "            .filterDate(start_date,end_date)"
      ],
      "metadata": {
        "id": "w-_8pKfCdxji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.5 Check the Image Information**\n",
        "Now we have downloaded the images. Let's review some information.\n",
        "First, let's take a look at how many images we got from the selection period. Landsat 8's temporal resolution is 16 days. Our selection period is 3 months. Hence, we should get at least 6 images. ((3*30)/16 = 5.6)"
      ],
      "metadata": {
        "id": "kTHHy5d5qdnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many images we get during the selection period.\n",
        "print('Total number:', landsat.size().getInfo())"
      ],
      "metadata": {
        "id": "qIQfDZIMd2ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we use the first image we pulled to see what information we can get."
      ],
      "metadata": {
        "id": "96e2zc8JuBor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "landsat.first().getInfo()"
      ],
      "metadata": {
        "id": "UXkCGwsUd5XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One key element in satellite imagery is how much of the image is covered by clouds. An image with heavy cloud coverage will not provide much information for our analysis. We usually would like the cloud coverage of an image to be around or below 0.05. Let's take a look the scale of cloud coverage in the first image."
      ],
      "metadata": {
        "id": "cs6f7q82uPQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "landsat.first().get('CLOUD_COVER').getInfo()"
      ],
      "metadata": {
        "id": "qyTjgo0Fd8vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the cloud coverage of the first image is 0.05, which is good. Now let's check when the first image was taken."
      ],
      "metadata": {
        "id": "Cy6OLDr5u21h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "landsat.first().get('DATE_ACQUIRED').getInfo()"
      ],
      "metadata": {
        "id": "zpru9TWLd_ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next thing we can check is the band names we get."
      ],
      "metadata": {
        "id": "-EIHksLGeCOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "landsat.first().bandNames().getInfo()"
      ],
      "metadata": {
        "id": "8DxiwoUkeDh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see from the above code results that there are more than 11 bands we learned from the previous section. The band names with 'ST_' are all under one band. They are sub-bands for the Aerosol band."
      ],
      "metadata": {
        "id": "hxeX14dxwHo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.6  Visualize Images**\n",
        "We are now ready to see the images we pulled. First, let's create labels for images to be used in the following visualization."
      ],
      "metadata": {
        "id": "1eqogE72xC4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put the images in a list\n",
        "landsat_list = landsat.toList(landsat.size());\n",
        "\n",
        "#Create labels for images\n",
        "labels = [\"Image #\"+str(i)+\", \"+str(ee.Image(landsat_list.get(i)).get('DATE_ACQUIRED').getInfo())+\", Cloud cover:\"+ str(ee.Image(landsat_list.get(i)).get('CLOUD_COVER').getInfo()) for i in range(landsat.size().getInfo())]\n",
        "labels"
      ],
      "metadata": {
        "id": "z-RkCzMsw6p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the image labels, we can see we have 8 images from image 0 to image 7. We also see the dates they were taken on and their cloud coverage index."
      ],
      "metadata": {
        "id": "ssWUXJgaxpTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define some parameters to display the images. We will use red, green, and blue bands to compose an image that resembles a photo. We will also define the pixel dimensions to show in our image. Last, we set the brightness by assigning min and max values. Assign values to min and max is a trial-and-error process. You need to play around with the number to get the appropriate brightness for images."
      ],
      "metadata": {
        "id": "hnbxuLCgiuYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "                'min': 7000,\n",
        "                'max': 16000,\n",
        "                'dimensions': 800, # square size in pixels\n",
        "                'bands': ['SR_B4', 'SR_B3', 'SR_B2'] # bands to display (r,g,b)\n",
        "             }"
      ],
      "metadata": {
        "id": "kONQSXlDixIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use geemap to display the first image overlayed on a map."
      ],
      "metadata": {
        "id": "LaF6MLqU0xZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Map = geemap.Map()\n",
        "\n",
        "first_image = landsat.first()\n",
        "\n",
        "Map.addLayer(first_image, parameters, \"First_Image\")\n",
        "Map.setCenter(lon,lat,8)\n",
        "Map"
      ],
      "metadata": {
        "id": "xj9V40gy-rfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above map, you can see the first image from our image collection. This is the image shot on November 7, 2018. You can move your cursor onto the map and move the map around. You can zoom in and out of the image by clicking the \"+\" or \"-\" icon on the left side of the map.\n",
        "<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "01K9mWWv1Gib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just saw how to display an image on the map. What if we want to interactively display other images in our collection on the map? We will create a new map and add a time series slider on the map to achieve this goal."
      ],
      "metadata": {
        "id": "LJFvjlPQ18E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = landsat.toBands()\n",
        "\n",
        "Map2 = geemap.Map()\n",
        "Map2.addLayer(image,{},\"Time series\", False)\n",
        "Map2.setCenter(lon,lat,8)\n",
        "Map2.add_time_slider(landsat, parameters, labels = labels, time_interval=1)\n",
        "Map2"
      ],
      "metadata": {
        "id": "-sY1AJ4VDs8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the new map has a slider on the lower right side of the map. **A note on using the slider:** Due to some technical issues, please do not use the \"Play the time slider\" button.\n",
        "\n",
        "On the slider, you can see the label of the first image (image #0) by the slider bar. If you move your cursor to the dot on the left of the slider bar, you will see the dot turns blue. You can then move the blue dot along the slider bar to see other images. The label will display the image information you are seeing on the map. For example, in image #3, there is heavy cloud cover, with the cloud coverage at 67, so most of what we see is white. If we move to image #5, its cloud coverage is 6, so we can get a better look at Earth's surface."
      ],
      "metadata": {
        "id": "lBZsHEkv3-gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.7 Select and Zoom in on Cloudless Images**\n",
        "We have investigated all the images we pulled from the data catalog. Now we would like to select the ones we will use for analysis. We would like to select 3 cloudless images: one from before the fire, one during the fire, and one after the fire. We would also like to zoom in on the area we are interested in for each image. By investigating all 8 images, we can see image #0, image #2, and image #5 fit our selection criteria."
      ],
      "metadata": {
        "id": "YnAQSeLQ6Yvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Select images we want and create a new image collection\n",
        "img1 = ee.Image(landsat_list.get(0))\n",
        "img2 = ee.Image(landsat_list.get(2))\n",
        "img3 = ee.Image(landsat_list.get(5))\n",
        "\n",
        "landsat_2 = ee.ImageCollection.fromImages([img1, img2, img3])\n",
        "print('Total number:', landsat_2.size().getInfo())"
      ],
      "metadata": {
        "id": "PC1QzkNjEScq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create new labels for a new collection of images. We also update our new visualization parameters."
      ],
      "metadata": {
        "id": "EbY0bmLTIbT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list\n",
        "landsat_list_2 = landsat_2.toList(landsat_2.size())\n",
        "\n",
        "# Define a region of interest with a buffer zone\n",
        "roi = poi.buffer(20000) # meters\n",
        "\n",
        "# New visualization parameters\n",
        "parameters_2 = {\n",
        "                'min': 6000,\n",
        "                'max': 16000,\n",
        "                'dimensions': 800,\n",
        "                'bands': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
        "                'region':roi\n",
        "             }\n",
        "\n",
        "#Create new labels for images\n",
        "labels_2 = [\"Image #\"+str(i)+\", \"+str(ee.Image(landsat_list_2.get(i)).get('DATE_ACQUIRED').getInfo())+\", Cloud cover:\"+ str(ee.Image(landsat_list_2.get(i)).get('CLOUD_COVER').getInfo()) for i in range(landsat_2.size().getInfo())]\n",
        "labels_2"
      ],
      "metadata": {
        "id": "2lg35dxUjXdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image2 = landsat_2.toBands()\n",
        "\n",
        "Map3 = geemap.Map()\n",
        "Map3.addLayer(image2,{},\"Time series\", False)\n",
        "Map3.setCenter(lon,lat,8)\n",
        "Map3.add_time_slider(landsat_2, parameters_2, labels = labels_2, time_interval=1)\n",
        "Map3"
      ],
      "metadata": {
        "id": "Ts-guiM_aS9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the upper corner of the middle image does show the fire. However, it is still hard to see the impact of the fire when comparing the first image to the last image. Let's introduce an NDVI index to better study the damage."
      ],
      "metadata": {
        "id": "RbdE5xPVJcqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.8 Normalized Difference Vegetation Index (NDVI)**\n",
        "The Normalized Difference Vegetation Index (NDVI) is an index to study plant health. This index is calculated by using reflected light from the red band and near infrared band of satellite images. The higher the index number means the plants are healthier and greener. The lower the index number means the plants are browner and less healthy. The concept is illustrated in Figure 7.\n",
        "<br>\n",
        "<br>\n",
        "**Figure 7. NDVI Illustration**\n",
        "![alt text](https://drive.google.com/uc?id=1sQF7SKkFZGfL-dSvY_EiubYPBd4_44km)\n",
        "<br>\n",
        "<br>\n",
        "In the following section, we will turn our three images into NDVI images. Each pixel will have an NDVI number. A pixel with a high NDVI number will be painted green. A pixel with a low NDVI number will be painted red. If the NDVI number is in between, the pixel will be painted yellow.\n",
        "\n"
      ],
      "metadata": {
        "id": "H-mJXTrXLVlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's calculate NDVI numbers for each image."
      ],
      "metadata": {
        "id": "slNVrMdMSswQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate NDVI for each image\n",
        "img_ndvi_1 = ee.Image(landsat_list_2.get(0)).normalizedDifference(['SR_B5', 'SR_B4'])\n",
        "img_ndvi_2 = ee.Image(landsat_list_2.get(1)).normalizedDifference(['SR_B5', 'SR_B4'])\n",
        "img_ndvi_3 = ee.Image(landsat_list_2.get(2)).normalizedDifference(['SR_B5', 'SR_B4'])\n",
        "\n",
        "landsat_3 = ee.ImageCollection.fromImages([img_ndvi_1, img_ndvi_2, img_ndvi_3])\n",
        "print('Total number:', landsat_3.size().getInfo())"
      ],
      "metadata": {
        "id": "8IoazdJyjhc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we'll set up the new color palette and NDVI visualization parameters."
      ],
      "metadata": {
        "id": "rcOTYTYGS1OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new list\n",
        "landsat_list_3 = landsat_3.toList(landsat_3.size())\n",
        "\n",
        "# ndvi palette: red is low, green is high vegetation\n",
        "palette = ['red', 'yellow', 'green']\n",
        "\n",
        "ndvi_parameters = {'min': 0,\n",
        "                   'max': 0.4,\n",
        "                   'dimensions': 512,\n",
        "                   'palette': palette,\n",
        "                   'region': roi}\n"
      ],
      "metadata": {
        "id": "rYqh-eVsN7lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's display the NDVI images."
      ],
      "metadata": {
        "id": "1c3DOq8eS9ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image3 = landsat_3.toBands()\n",
        "\n",
        "Map4 = geemap.Map()\n",
        "Map4.addLayer(image3,{},\"Time series\", False)\n",
        "Map4.setCenter(lon,lat,8)\n",
        "Map4.add_time_slider(landsat_3, ndvi_parameters, labels = labels_2, time_interval=1)\n",
        "Map4"
      ],
      "metadata": {
        "id": "d6FgZ76OORJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above interactive NDVI images, let's focus on the upper middle part of each image. Let's start with image #0.\n",
        "\n",
        "In image #0, the area contains a mixture of green, yellow, and red. This image was taken before the Camp Fire. In image #1, we can see a big swath of red running across the area from right to left and going down. This image was taken during the Camp Fire. The red area is where the fire was. Now let's look at image #3, which was taken after the Camp Fire. In image #3, we can see a big red area in the upper middle part and some on the upper left side of the image. To summarize, with NDVI images, we can better identify changes in the vegetation on Earth's surface."
      ],
      "metadata": {
        "id": "cdWYm1yFc1OJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Conclusion**\n",
        "In this lesson, we first learned the basics of remote sensing, the method to obtain satellite images. We then went through the fundamentals of satellite images, including the electromagnetic spectrum, spatial resolution, and commonly used satellites. We then introduced some use cases for applying satellite images to finance analyses. We finished the lesson by using Google Earth Engine's Python API to pull some satellite images and conducted some analysis. We learned to use NDVI images to investigate the vegetation damage after the 2018 Camp Fire in California."
      ],
      "metadata": {
        "id": "di8BpMzLkMR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**References**\n",
        "* NASA EarthData. \"Remote Sensing.\" 10 December 2024. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n",
        "\n",
        "* UCLA Office of Advanced Research Computing. \"Introduction to Remote Sensing With Python.\" *YouTube*, 9 Feb 2022, https://www.youtube.com/watch?v=gi4UdFsayoM."
      ],
      "metadata": {
        "id": "NaeoQbgGmsnl"
      }
    }
  ]
}